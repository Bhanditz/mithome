Title: Seeing Dandelions
Date: 2016-04-24 13:29
Category: Blog

I spent the morning with my son Cody digging dandelions out of our lawn.
Some dandelions are easy to spot since they are sprouting yellow flowers,
but other dandelions are harder to see.  Cody helped me on the hunt.
Also, since dandelions spread out, when you dig them out, you need to
also look carefully to find the center of the plant to locate
the taproot.  We filled half of a trash bag full of dandelions.

My brain doing an odd thing now that I am resting.  Whenever I close my
eyes, I see dandelion plants, a different plant each time I blink.
My brain is imagining symmetric top-down images of these plants,
with white and red veins radiating from center, festooned with spiked
green leaves.  This is not how I saw the plants in the garden: I spotted
them from far away in diagonal and side-view.  But I am now replaying
images of dandelions in a abstract symmetrical circular perfection.

What is my brain doing?  Neuroscientists have long suspected that
memories "consolidate" during rest. But recently, a
[Nature Neuroscience paper by H Freyja Ólafsdóttir](http://www.nature.com/neuro/journal/vaop/ncurrent/full/nn.4291.html)
actually measured this!  The UCL scientists measured rat brains
during 30 minutes of running on a track, and then during 90 minutes
of rest afterwards. During rest, the rat brains
reproduced the signals of their experience running on the track,
but replaying the experience 10-20 times faster than realtime.

It is interesting to contemplate why replay is necessary, or
what might be in the transformation between initial experience and
replay. For example, when training artificial neural networks,
programmers use "training set augmentation", applying transformations
on the training set data without altering labels, in order to
generate a larger training set. Is this what consolidation is
all about?

Or it is the opposite?  My brain seems to be imagining
canonicalized dandelions, centered in the field of view with
perspective skew removed.  Is it canonicalizing the view for
better compression?  Should we be trying to do the same thing
in artificial neural networks?
